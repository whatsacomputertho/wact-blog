
<p>While &#8203;using the &#8203;FootballSim MVP &#8203;to &#8203;simulate &#8203;our
  &#8203; mini football &#8203;league, &#8203;we &#8203;found &#8203;that &#8203;the
  model &#8203;would &#8203;regularly &#8203;spit &#8203;out &#8203;scores &#8203;that&#160;
  &#8203;are &#8203;unlikely in &#8203;a &#8203;real &#8203;football &#8203;game. &#8203;
  &#8203;For &#8203;example, &#8203;we &#8203;simulated one &#8203;game &#8203;which
  ended &#8203;in &#8203;a &#8203;25-22 &#8203;final &#8203;score. &#8203; &#8203;This
  final &#8203;score &#8203;isn't &#8203;technically &#8203;impossible, &#8203;but
  each component of &#8203;the &#8203;score &#8203;is &#8203;one &#8203;off &#8203;from&#160;
  &#8203;a &#8203;much &#8203;more &#8203;likely score &#8203;of &#8203;24-21.</p>
<p>Statistically speaking, one &#8203;instance &#8203;of &#8203;an &#8203;unlikely&#160;
  &#8203;final &#8203;score &#8203;is &#8203;not indicative &#8203;of &#8203;a larger-scale
  &#8203;problem.&#160; &#8203;But &#8203;having &#8203;simulated &#8203;many &#8203;of&#160;
  &#8203;these games which &#8203;resulted &#8203;in &#8203;an unlikely &#8203;final
  &#8203; score, &#8203;we &#8203;had &#8203;a &#8203;growing intuition &#8203;that
  certain &#8203;scores &#8203;would be &#8203;observed far &#8203;too &#8203;frequently
  than &#8203;they &#8203;should &#8203;be. &#8203; &#8203;And &#8203;thus, &#8203;we
  &#8203; wanted to &#8203;investigate the problem &#8203;further.</p>
<h2 data-original-level="H2" id="header-fefb2e9c-b8a4-c98d-4978-72b9b1daf7b5">Score &#8203;Frequency Improvements</h2>
<h3 data-original-level="H3" id="header-3e56cffc-751c-6efc-74ff-d51456e98628">Exploratory &#8203;Data Analysis</h3>
<p>First, we needed &#8203;to &#8203;find the &#8203;overall frequency &#8203;of &#8203;observed
  scores &#8203;in &#8203;the real &#8203;world &#8203;data. &#8203; &#8203;We ran&#160;some&#160;
  &#8203;basic &#8203;data &#8203;analysis and produced the &#8203;following &#8203;historgram&#160;
  &#8203;depicting <a href="https://github.com/whatsacomputertho/fbdb-boxscore-eda/blob/main/data/preprocessed/frequency.json" target="_blank">the ​frequency ​of ​real football ​scores</a>.</p>
<media-image source="files/score-frequency.png" card citation="Frequency of real football scores" accent-color="grey" size="wide" offset="none"></media-image>
<p>Here &#8203;we &#8203;see that &#8203;the frequency of the &#8203;score &#8203;24
  and &#8203;the &#8203;score &#8203;25 differ by &#8203;a &#8203;factor &#8203;of&#160;
  &#8203;10, and &#8203;the &#8203;frequency of &#8203;the &#8203;score &#8203;22 &#8203;and&#160;
  &#8203;the &#8203;score &#8203;21 &#8203;differ &#8203;by &#8203;a &#8203;factor
  &#8203;of &#8203;4.&#160; &#8203;So &#8203;the intuitive sense of &#8203;the &#8203;score
  &#8203; 25-22 &#8203;being &#8203;much less likely &#8203;than, say 24-21, &#8203;is
  &#8203; backed up by this data.&#8203;</p>
<p>Now &#8203;what &#8203;sort of &#8203;distribution &#8203;does &#8203;the model
  &#8203; produce &#8203;today? &#8203; &#8203;To &#8203;answer &#8203;this &#8203;question,
  <a href="https://github.com/whatsacomputertho/fbsim-cli/blob/daef08825329d28a86b05e9bfad7e74faa42888f/src/main.rs#L70-L246" target="_blank">​I ​developed ​a ​new ​command ​in ​fbsim-cli</a>, <code>fbsim ​game ​benchmark</code>.
    &#8203; &#8203;This &#8203;command &#8203;runs &#8203;1.2 million &#8203;simulations,
    &#8203; and then aggregates the results of &#8203;the &#8203;simulations to show us&#160;
    &#8203;how &#8203;the &#8203;model performs &#8203;statistically.&#160; &#8203;Over
    &#8203;time, &#8203;we &#8203;want &#8203;to &#8203;improve &#8203;the &#8203;model's
    &#8203; statistical accuracy &#8203;when tested using &#8203;this &#8203;benchmark&#160;
    &#8203;test.</p>
<p>I &#8203;then &#8203;<a href="https://github.com/whatsacomputertho/fbdb-boxscore-eda/pull/9" target="_blank">plotted ​the ​data ​from ​the ​benchmark ​test ​against ​fbsim-core ​v1.0.0-alpha.3</a> in
  &#8203; another histogram &#8203;plot.</p>
<media-image source="files/base_model_score_frequency.png" card citation="The frequency of observed scores in the base FootballSim model" accent-color="grey" size="wide" offset="none"></media-image>
<p>This &#8203;is &#8203;pretty &#8203;much &#8203;a &#8203;perfect &#8203;normal &#8203;curve,
  with no &#8203;local &#8203;fuzziness.&#160; This means &#8203;a final score &#8203;of
  &#8203;25 &#8203;is &#8203;achieved with roughly &#8203;the &#8203;same &#8203;frequency
  as 24 &#8203;despite &#8203;their &#8203;real-world &#8203;10x difference &#8203;in
  &#8203;frequency.&#160; &#8203;It's &#8203;also centered &#8203;mysteriously &#8203;high
  when &#8203;compared &#8203;against &#8203;the &#8203;real &#8203;data, which &#8203;we'll
  investigate &#8203;shortly.</p>
<h3 data-original-level="H3" id="header-9c4a6670-d911-76bb-4ffb-77272d125e75">Score &#8203;Frequency &#8203;Lookup &#8203;Table &#8203;Filtering</h3>
<p>To attempt &#8203;to &#8203;solve &#8203;the &#8203;frequency &#8203;problem, I
  decided &#8203;to &#8203;take &#8203;the &#8203;following &#8203;approach.&#160;
  &#8203;I would <a href="https://github.com/whatsacomputertho/fbsim-core/blob/main/src/freq.rs" target="_blank">pre-load a ​lookup ​table with the actual ​observed ​frequencies for ​each ​score</a>.
  &#8203; &#8203;Then upon &#8203;generating &#8203;a &#8203;score, &#8203;I &#8203;would&#160; &#8203;<a href="https://github.com/whatsacomputertho/fbsim-core/blob/3d166fed5bea327f02931a5b504bfb67dfd2220a/src/sim.rs#L146-L171" target="_blank">adjust ​it ​using the ​lookup ​table</a>.</p>
<ul>
  <li role="textbox">First, I ​​lookup the ​generated ​score N, as ​well ​as ​its neighboring ​scores 
    ​N-1 and ​N+1</li>
  <li role="textbox">​Then ​I ​construct ​a ​categorical ​distribution over ​those ​three ​scores where
    their probability is scaled relative to their observed frequency from the lookup
    table</li>
  <li role="textbox">Finally, I ​randomly ​draw a ​score ​from the ​distribution to ​get ​the ​adjusted
    ​ score</li>
</ul>
<p>This &#8203;seemed &#8203;to have &#8203;a &#8203;positive &#8203;effect &#8203;on&#160;
  &#8203;score &#8203;frequency.&#160; We began to see &#8203;the more frequently observed&#160;
  &#8203;final scores &#8203;appearing &#8203;more &#8203;often in our simulations.</p>
<media-image source="files/adj_model_score_frequency.png" card citation="The frequency of observed scores in the adjusted FootballSim model" accent-color="grey" size="wide" offset="none"></media-image>
<p>Beyond intuition, &#8203;what sort &#8203;of &#8203;effect &#8203;did &#8203;it&#160;
    &#8203;have &#8203;on &#8203;the &#8203;model's &#8203;statistical performance?&#160;Visually,
    &#8203;this &#8203;looks &#8203;like &#8203;a &#8203;much &#8203;better &#8203;fit
    &#8203; in &#8203;comparison &#8203;to &#8203;the original &#8203;model.&#160; &#8203;Further
    comparing the &#8203;mean &#8203;squared &#8203;errors for &#8203;the &#8203;base
    &#8203; and &#8203;adjusted &#8203;model score frequencies &#8203;against &#8203;the
    &#8203; real &#8203;data &#8203;supports &#8203;the &#8203;fact &#8203;that &#8203;this
    is, &#8203;by and &#8203;large, &#8203;an improvement.</p>
<code-sample type="javascript" copy-clipboard-button>
    
  <template preserve-content="preserve-content">Base model mean squared error: 7.5289
Adj model mean squared error:  4.1097</template></code-sample>
<p>You &#8203;may &#8203;also &#8203;have &#8203;noticed &#8203;that, between &#8203;the
    &#8203; base &#8203;model &#8203;and &#8203;the &#8203;adjusted &#8203;model, &#8203;not
    only did &#8203;the &#8203;model's &#8203;local &#8203;behavior &#8203;change, &#8203;but
    &#8203; so &#8203;did &#8203;its &#8203;global &#8203;behavior - it &#8203;is &#8203;now&#160;
    &#8203;centered &#8203;more &#8203;appropriately.&#160; &#8203;This &#8203;is &#8203;no&#160;
    &#8203;mistake, &#8203;I &#8203;actually found &#8203;a &#8203;major bug &#8203;in&#160;
    &#8203;the process &#8203;of &#8203;validating the &#8203;model &#8203;with <code>​fbsim ​game ​benchmark</code> &#8203;which
    I &#8203;fixed &#8203;in between &#8203;producing &#8203;those &#8203;two &#8203;histograms.</p>
<h2 data-original-level="H2" id="header-afba05e7-4ac9-764a-e943-fea0cb88a5b7">Benchmark Test &#8203;Findings &#8203;&#38; &#8203;Bug &#8203;Fixes</h2>
<p>Let's &#8203;take &#8203;a &#8203;quick &#8203;detour to &#8203;talk about &#8203;some
      tangential findings I made during benchmark testing (and their subsequent bug fixes)
      &#8203; before &#8203;moving onto the tie frequency enhancements I made.</p>
<h3 data-original-level="H3" id="header-0513e28c-1e40-a2f6-b626-380e5659c81b">Why &#8203;was &#8203;the &#8203;score &#8203;frequency &#8203;distribution &#8203;off-center?</h3>
<p>In &#8203;the &#8203;<code>fbsim ​game ​benchmark</code> &#8203;CLI command, &#8203;I
      &#8203; produce &#8203;a table &#8203;which &#8203;lists the &#8203;skill &#8203;differential
      alongside &#8203;the &#8203;observed mean &#8203;and &#8203;standard deviation &#8203;score
      &#8203; for &#8203;both &#8203;the &#8203;home &#8203;and &#8203;away &#8203;teams.
      &#8203; &#8203;When &#8203;I &#8203;was &#8203;benchmark &#8203;testing &#8203;the
      &#8203; model, &#8203;I &#8203;noticed &#8203;that &#8203;the observed mean &#8203;score
      &#8203; was way off &#8203;from &#8203;what &#8203;it &#8203;should &#8203;have &#8203;been.</p>
<p>Here &#8203;is &#8203;the &#8203;output &#8203;from &#8203;the &#8203;benchmark
      &#8203; test:</p>
<code-sample type="javascript" copy-clipboard-button>
      
    <template preserve-content="preserve-content">Home score distribution:
Skill Diff   Mean Score   Std Score
-100         23.1506      7.6162
-80          24.2101      8.1887
-60          25.3185      8.6021
-40          26.4397      8.9407
-20          27.5418      9.2587
0            28.6667      9.4145
20           29.7236      9.5225
40           30.8259      9.5603
60           31.8998      9.4884
80           33.0837      9.3034
100          34.1129      9.0627

Away score distribution:
Skill Diff   Mean Score   Std Score
-100         22.1655      6.4798
-80          23.0604      7.2377
-60          23.9255      7.8504
-40          24.8286      8.3757
-20          25.7620      8.7426
0            26.6536      9.0463
20           27.5140      9.2175
40           28.4326      9.3427
60           29.2490      9.2932
80           30.1968      9.1622
100          31.0702      8.9115</template></code-sample>
<p>While the mean score model &#8203;was &#8203;fit &#8203;against &#8203;this &#8203;data
      for &#8203;home &#8203;teams:</p>
<code-sample type="json" copy-clipboard-button>
      
    <template preserve-content="preserve-content">"('score', 'mean')": {
  "0.0": 11.5590551181,
  "0.125": 13.8620155039,
  "0.25": 17.0134387352,
  "0.375": 19.1485774499,
  "0.5": 22.3723214286,
  "0.625": 24.8021442495,
  "0.75": 27.5766828591,
  "0.875": 31.6327372765,
  "1.0": 34.9343434343
}</template></code-sample>
<p>and &#8203;similarly &#8203;for &#8203;away &#8203;teams:</p>
<code-sample type="json" copy-clipboard-button>
      
    <template preserve-content="preserve-content">"('score', 'mean')": {
  "0.0": 9.3671875,
  "0.125": 12.2220421394,
  "0.25": 14.2501797268,
  "0.375": 16.8838776568,
  "0.5": 19.3722963645,
  "0.625": 22.0789733465,
  "0.75": 25.3302358828,
  "0.875": 28.9319444444,
  "1.0": 31.5263157895
}</template></code-sample>
<p>The &#8203;upper &#8203;end &#8203;of &#8203;the &#8203;spectrum for both home and
      away teams seems &#8203;to &#8203;be &#8203;roughly &#8203;aligned, but &#8203;the
      &#8203; lower &#8203;end &#8203;of &#8203;the &#8203;spectrum &#8203;seems &#8203;to&#160;
      &#8203;be extremely misaligned.&#160; &#8203;This &#8203;is &#8203;what &#8203;was
      &#8203; producing &#8203;the misalignment &#8203;in &#8203;the &#8203;centering of
      the base model &#8203;score &#8203;frequency &#8203;distribution &#8203;that &#8203;we&#160;
      &#8203;saw &#8203;earlier!</p>
<p>Reflecting on &#8203;this, &#8203;my &#8203;brother &#8203;and &#8203;I &#8203;did
      &#8203; notice in &#8203;our &#8203;mini &#8203;football &#8203;league &#8203;that
      &#8203; there &#8203;were &#8203;a &#8203;few surprise contenders which &#8203;had
      &#8203; beaten multiple opponents &#8203;much &#8203;better &#8203;than &#8203;they
      &#8203; were. &#8203; &#8203;We figured our &#8203;intuition &#8203;around &#8203;skill&#160;
      &#8203;differential and win probability might &#8203;&#8203;just be &#8203;outright&#160;
      &#8203;wrong, but as it turns out we were just being gas-lit by this bug in the model.</p>
<p>So &#8203;what &#8203;was &#8203;causing &#8203;this bug? &#8203; &#8203;Well, it
      &#8203; was &#8203;a &#8203;stupid &#8203;one - &#8203;a &#8203;simple &#8203;typo!
      &#8203; &#8203;I &#8203;had &#8203;accidentally <a href="https://github.com/whatsacomputertho/fbsim-core/pull/20/files#diff-ea46a6f4f599d033be920bb2c53a6cae98acb3483cafa763e782cab40bfd9cf3L10-R18" target="_blank">misnamed the ​constant names ​for ​the ​regression ​models' ​intercepts ​and coefficients</a>,
      which &#8203;resulted &#8203;in &#8203;the &#8203;intercept &#8203;being treated
      &#8203;as the &#8203;coefficient, &#8203;and &#8203;vice &#8203;versa. &#8203; &#8203;
      <a href="https://github.com/whatsacomputertho/fbsim-core/pull/20" target="_blank">I ​fixed ​that ​issue ​in ​this ​PR</a>, &#8203;and &#8203;subsequently &#8203;saw&#160;
        &#8203;much &#8203;better &#8203;results &#8203;in &#8203;the benchmark &#8203;testing.</p>
<code-sample type="javascript" copy-clipboard-button>
      
      <template preserve-content="preserve-content">Home score distribution:
Skill Diff   Mean Score   Std Score
-100         11.2780      7.1944
-80          13.4964      7.8423
-60          15.7159      8.3578
-40          18.0300      8.8404
-20          20.3076      9.1898
0            22.5839      9.4275
20           24.9194      9.5291
40           27.2036      9.5548
60           29.5982      9.4513
80           31.8540      9.2936
100          34.2193      9.0829

Away score distribution:
Skill Diff   Mean Score   Std Score
-100         9.1762       6.0629
-80          11.3444      6.8845
-60          13.4862      7.5883
-40          15.6616      8.1947
-20          17.7987      8.6510
0            20.0065      9.0046
20           22.2411      9.2066
40           24.4323      9.3496
60           26.7023      9.3638
80           28.9100      9.1980
100          31.1470      8.9210</template></code-sample>
<h3 data-original-level="H3" id="header-0b3a7445-4360-355e-a9c8-4472991ce4fa">Simulation &#8203;speed &#8203;regression</h3>
<p>While comparing the output of &#8203;fbsim-core &#8203;v1.0.0-alpha.3 (pre-score
        frequency enhancement) &#8203;and &#8203;v1.0.0-alpha.13 in &#8203;terms &#8203;of
        &#8203;their &#8203;statistical &#8203;performance, I &#8203;noticed that there &#8203;was
        &#8203; a &#8203;huge &#8203;difference &#8203;in &#8203;how &#8203;long &#8203;it&#160;
        &#8203;took &#8203;to &#8203;simulate &#8203;1.2 million &#8203;games &#8203;across&#160;
        &#8203;the &#8203;versions.</p>
<ul>
        <li role="textbox">In ​v1.0.0-alpha.3, it ​took ​<b>5.63 ​seconds</b> ​to ​simulate 1.2 ​million ​games</li>
        <li role="textbox">In ​v1.0.0-alpha.13, it ​took ​<b>90.29 ​seconds</b> ​to ​simulate ​1.2 ​million
          ​games</li>
      </ul>
<p>So &#8203;in &#8203;the &#8203;process &#8203;of &#8203;fixing &#8203;the &#8203;statistical&#160;
        &#8203;performance &#8203;issue, &#8203;I &#8203;made a &#8203;major &#8203;tradeoff&#160; &#8203;in &#8203;terms &#8203;of &#8203;speed. &#8203; &#8203;What &#8203;happened?&#160;
        Well, &#8203;looking back &#8203;at &#8203;the &#8203;source &#8203;code, &#8203;I&#160;
        &#8203;found &#8203;that &#8203;I'm &#8203;doing &#8203;some &#8203;pretty &#8203;stupid&#160;
        &#8203;things &#8203;that are &#8203;likely &#8203;causing &#8203;this speed &#8203;regression.</p>
<code-sample type="javascript" copy-clipboard-button>
        
        <template preserve-content="preserve-content">/// Filters the box score by score frequency. The score's nearest
/// neighbors and their frequency are retrieved to construct a probability
/// mass function for a categorical distribution. That distribution is
/// then sampled for the real score.
fn filter_score(&amp;self, score: i32, rng: &amp;mut impl Rng) -&gt; i32 {
  // If the score is 0, just return 0 as 1 is impossible
  if score == 0 { return 0 }
  
  // Create a score frequency lookup table
  let mut freq_lut = ScoreFrequencyLookup::new();
  freq_lut.create();
  
  // Get the nearest neighbors of the score
  let low = freq_lut.frequency(score - 1).unwrap();
  let mid = freq_lut.frequency(score).unwrap();
  let high = freq_lut.frequency(score + 1).unwrap();
  
  // Construct a categorical distribution
  let dist = Categorical::new(&amp;[low as f64, mid as f64, high as f64]).unwrap();
  let score_adjustment_r: f64 = dist.sample(rng);
  let score_adjustment = (score_adjustment_r as i32) - 1_i32;
  let adj_score = score + score_adjustment;
  adj_score
}</template></code-sample>
<p>First, I &#8203;am &#8203;allocating &#8203;and &#8203;de-allocating &#8203;the
          &#8203; score &#8203;frequency &#8203;distribution &#8203;every &#8203;time &#8203;I
          run &#8203;a &#8203;simulation. &#8203; &#8203;Alternatively, I &#8203;could &#8203;simply
          store &#8203;a &#8203;static &#8203;reference &#8203;to &#8203;an immutable lookup
          table &#8203;that &#8203;I only instantiate &#8203;once.</p>
<p>&#8203;Second, &#8203;I &#8203;am &#8203;using a &#8203;<code>BTreeMap</code> to
          store the lookup table, which has O(log N) lookup performance, &#8203;and &#8203;not
          &#8203; a &#8203;<code>HashMap</code> which has O(1) lookup performance.&#160; &#8203;Granted,&#160;
          &#8203;my &#8203;lookup &#8203;table is &#8203;only &#8203;size-80 &#8203;so &#8203;this&#160;
          &#8203;may &#8203;not &#8203;be &#8203;all &#8203;that &#8203;much &#8203;of a &#8203;contributor,
          but &#8203;it's &#8203;a &#8203;simple &#8203;change &#8203;to &#8203;switch &#8203;between&#160;
          &#8203;collections &#8203;under &#8203;the &#8203;hood, &#8203;so &#8203;may &#8203;as
          &#8203; well &#8203;do so while &#8203;I'm &#8203;looking &#8203;at &#8203;performance.</p>
<p>I &#8203;released fbsim-core &#8203;v1.0.0-alpha.14 &#8203;<a href="https://github.com/whatsacomputertho/fbsim-core/pull/24" target="_blank">which includes these ​changes</a> &#8203;and &#8203;then &#8203;re-ran
          &#8203; the &#8203;benchmark &#8203;testing.&#160; &#8203;This time, &#8203;I &#8203;was
          able &#8203;to &#8203;run &#8203;1.2 &#8203;million &#8203;simulations in &#8203;just
          &#8203;<b> 8.18 ​seconds</b>, &#8203;bringing &#8203;us &#8203;back &#8203;down &#8203;into
          &#8203; a &#8203;reasonable &#8203;range.</p>
<h2 data-original-level="H2" id="header-4018027a-7794-69f4-d6b9-fdbb6f1f02bb">Tie &#8203;Frequency &#8203;Improvements</h2>
<p>The &#8203;natural &#8203;question &#8203;we &#8203;asked &#8203;upon &#8203;making&#160;
          &#8203;the aforementioned improvement &#8203;to &#8203;&#8203;score &#8203;frequency
          was, &#8203;how &#8203;does &#8203;this &#8203;impact the &#8203;frequency &#8203;of
          &#8203; ties? &#8203; &#8203;If &#8203;some scores are more likely than others, &#8203;does&#160;
          &#8203;that now&#160;&#8203;mean &#8203;that &#8203;we will observe more &#8203;ties&#160;
          &#8203;which &#8203;would &#8203;have &#8203;otherwise been &#8203;one-point &#8203;victories?</p>
<p>To &#8203;answer &#8203;these &#8203;questions, &#8203;we &#8203;again &#8203;compared
          the <code>​fbsim ​game ​benchmark</code> &#8203;testing against &#8203;real-world &#8203;data.&#160;
          &#8203;Ultimately, the &#8203;question &#8203;we &#8203;ended &#8203;up &#8203;looking&#160;
          &#8203;into &#8203;the &#8203;most &#8203;was &#8203;simply - how do &#8203;we fit
          the &#8203;real-world football &#8203;tie &#8203;frequency?</p>
<h3 data-original-level="H3" id="header-4ef0fba9-80c9-fa79-7060-c2a79320f924">Exploratory &#8203;Data &#8203;Analysis</h3>
<p>The &#8203;first &#8203;thing &#8203;I &#8203;did as a &#8203;sanity check was &#8203;calculate
          the &#8203;real-world global tie &#8203;probability, which &#8203;worked &#8203;out
          &#8203;to &#8203;be roughly <code>​p_tie ​= ​0.006</code>. &#8203; &#8203;Then &#8203;I
          &#8203; used &#8203;fbsim &#8203;game &#8203;benchmark &#8203;to &#8203;compare &#8203;this
          against &#8203;the model, whose &#8203;tie probability &#8203;ended &#8203;up &#8203;being <code>​p_tie ​= 0.042</code>.&#160;
          &#8203;That means &#8203;my &#8203;model is &#8203;7x &#8203;more &#8203;likely to
          &#8203; produce &#8203;a &#8203;tie &#8203;than &#8203;it &#8203;should &#8203;be!</p>
<p>From &#8203;there, I &#8203;looked &#8203;into &#8203;the &#8203;likelihood &#8203;of
          &#8203; a &#8203;tie &#8203;based on &#8203;skill &#8203;differential.&#160; &#8203;That&#160;
          &#8203;is, are there roughly the &#8203;same &#8203;number &#8203;of &#8203;ties&#160;
          &#8203;observed when &#8203;teams &#8203;are evenly &#8203;matched as &#8203;there&#160;
          &#8203;are &#8203;when &#8203;teams &#8203;are mismatched &#8203;in &#8203;their&#160;
          &#8203;skill level?</p>
<p>As &#8203;one &#8203;might &#8203;expect, &#8203;I &#8203;found &#8203;that &#8203;ties
          are more &#8203;likely &#8203;when two &#8203;teams &#8203;are &#8203;evenly &#8203;matched,
          and &#8203;decrease &#8203;by &#8203;a &#8203;factor &#8203;of &#8203;10 &#8203;when&#160;
          &#8203;a team fully &#8203;outmatches &#8203;their opponent.</p>
<media-image source="files/tie_freq_by_skill_diff.png" card citation="Tie probability by skill differential linear regression" accent-color="grey" size="wide" offset="none" link="files/tie_freq_by_skill_diff.png" disable-zoom></media-image>
<p>I &#8203;ended &#8203;up &#8203;training &#8203;a &#8203;linear &#8203;regression&#160;
          &#8203;model &#8203;to &#8203;fit &#8203;the &#8203;data, and &#8203;planned &#8203;to
          &#8203; use &#8203;this &#8203;same &#8203;linear &#8203;regression &#8203;model &#8203;in&#160;
          &#8203;fbsim-core to &#8203;match the &#8203;observed &#8203;tie &#8203;probability.</p>
<h3 data-original-level="H3" id="header-6febb2b5-2dff-23d9-81df-649c48511f36">Tie Re-simulation</h3>
<p>The way in &#8203;which &#8203;I &#8203;planned &#8203;to &#8203;fit &#8203;this
            &#8203; observed tie &#8203;probability in &#8203;my &#8203;model &#8203;was &#8203;through
            re-simulating games with &#8203;some &#8203;probability &#8203;when &#8203;a &#8203;tie
            &#8203; is &#8203;achieved &#8203;on &#8203;the &#8203;first &#8203;simulation. &#8203;
            &#8203;This was &#8203;not &#8203;a &#8203;trivial &#8203;calculation, &#8203;so&#160;
            &#8203;let me &#8203;walk &#8203;you &#8203;through the logic &#8203;behind &#8203;it.</p>
<p>First, &#8203;we &#8203;will &#8203;note &#8203;that &#8203;the &#8203;&#8203;global &#8203;tie &#8203;probability that &#8203;we &#8203;observed &#8203;previously in
            &#8203; our &#8203;model &#8203;was &#8203;<code>p_tie ​= ​0.042</code>. &#8203; &#8203;Considering&#160;
            &#8203;this, &#8203;imagine &#8203;if &#8203;we &#8203;simply &#8203;simulated &#8203;all&#160;
            &#8203;games &#8203;that &#8203;ended &#8203;in &#8203;ties.&#160; &#8203;Then &#8203;the
            &#8203; probability &#8203;of &#8203;a &#8203;tie &#8203;occurring &#8203;in &#8203;this
            &#8203; case &#8203;would be:</p>
<p data-text-align="center"><lrn-math mathtext="p_{tie} = (0.042)^{2}  "><span>p_{tie} = (0.042)^{2}  </span></lrn-math>



</p>
<p data-text-align="center"><lrn-math mathtext="\implies p_{tie} = 0.001764"><span>\implies p_{tie} = 0.001764</span></lrn-math>


</p>
<p>Which &#8203;isn't &#8203;quite &#8203;the &#8203;global tie &#8203;probability &#8203;we &#8203;want.&#160; &#8203;Instead, we'll &#8203;need &#8203;to &#8203;strategically &#8203;calculate &#8203;a &#8203;re-simulation &#8203;probability to &#8203;fit &#8203;the observed tie &#8203;probability. &#8203; &#8203;To do &#8203;so, &#8203;we &#8203;will &#8203;need to &#8203;use &#8203;a &#8203;bit &#8203;of &#8203;probability &#8203;and basic arithmetic.</p>
<p>In &#8203;this &#8203;visualization, we &#8203;see a probability tree representing &#8203;the &#8203;outcome of &#8203;a &#8203;game simulation. The leaves &#8203;in &#8203;this &#8203;tree &#8203;are &#8203;the &#8203;outcomes, and &#8203;the &#8203;probability &#8203;of &#8203;that &#8203;outcome &#8203;occurring &#8203;can be &#8203;derived &#8203;by &#8203;multiplying &#8203;the &#8203;edges &#8203;leading to that &#8203;outcome.</p>
<media-image source="files/tie-resim-prob-tree.png" card accent-color="grey" size="wide" offset="none" link="files/tie-resim-prob-tree.png" citation="Probability tree of tie re-sim outcomes" disable-zoom></media-image>
<p>In &#8203;order &#8203;to &#8203;observe &#8203;a &#8203;particular &#8203;<lrn-math mathtext="p_{tie}"><span>p_{tie}</span></lrn-math>
, we &#8203;can solve &#8203;the &#8203;following &#8203;equality for <lrn-math mathtext="​p_{resim}"><span>​p_{resim}</span></lrn-math>
 &#8203;and set &#8203;the &#8203;re-sim &#8203;probability &#8203;accordingly.</p>
<p data-text-align="center"><lrn-math mathtext="p_{tie} = (0.042)^{2} p_{resim} + 0.042 (1-p_{resim})"><span>p_{tie} = (0.042)^{2} p_{resim} + 0.042 (1-p_{resim})</span></lrn-math>

</p>
<p data-text-align="center"><lrn-math mathtext="\implies p_{tie} = (0.042)^{2} p_{resim} + 0.042 -0.042 p_{resim}  "><span>\implies p_{tie} = (0.042)^{2} p_{resim} + 0.042 -0.042 p_{resim}  </span></lrn-math>

</p>
<p data-text-align="center"><lrn-math mathtext="\implies p_{tie} - 0.042 = (0.042)^{2} p_{resim} -0.042 p_{resim}  "><span>\implies p_{tie} - 0.042 = (0.042)^{2} p_{resim} -0.042 p_{resim}  </span></lrn-math>

</p>
<p data-text-align="center"><lrn-math mathtext="\implies p_{tie} - 0.042 = p_{resim} ((0.042)^{2} -0.042)    "><span>\implies p_{tie} - 0.042 = p_{resim} ((0.042)^{2} -0.042)    </span></lrn-math>

</p>
<p data-text-align="center"><lrn-math mathtext="\implies \frac{p_{tie} - 0.042}{(0.042)^{2} -0.042} = p_{resim}"><span>\implies \frac{p_{tie} - 0.042}{(0.042)^{2} -0.042} = p_{resim}</span></lrn-math>

</p>
<p>Now recall &#8203;that &#8203;we &#8203;implemented &#8203;a &#8203;regression &#8203;model &#8203;in &#8203;which &#8203;the <lrn-math mathtext="p_{tie}"><span>p_{tie}</span></lrn-math>
 varies based &#8203;on &#8203;skill differential.&#160; &#8203;To &#8203;decide <lrn-math mathtext="​p_{tie}"><span>​p_{tie}</span></lrn-math>
, we &#8203;will &#8203;calculate &#8203;the &#8203;skill &#8203;differential &#8203;in &#8203;both directions &#8203;(that &#8203;is, &#8203;home offense / away defense, and &#8203;vice versa), average &#8203;the &#8203;two, &#8203;and &#8203;fetch &#8203;<lrn-math mathtext="p_{tie}"><span>p_{tie}</span></lrn-math>
 &#8203;from &#8203;the &#8203;regression &#8203;model.</p>
<p>Then we &#8203;will &#8203;plug &#8203;the &#8203;fetched &#8203;<lrn-math mathtext="p_{tie}"><span>p_{tie}</span></lrn-math>
 &#8203;into &#8203;the &#8203;above &#8203;equation &#8203;to &#8203;get &#8203;<lrn-math mathtext="p_{resim}"><span>p_{resim}</span></lrn-math>
.&#160; &#8203;For example, &#8203;suppose &#8203;the teams &#8203;are &#8203;evenly matched. &#8203; &#8203;Then &#8203;<lrn-math mathtext="p_{tie} = 0.011"><span>p_{tie} = 0.011</span></lrn-math>
 &#8203;according to &#8203;our &#8203;regression &#8203;model. &#8203; &#8203;Plugging &#8203;that &#8203;into &#8203;the &#8203;equation, &#8203;we &#8203;get &#8203;the &#8203;following &#8203;re-sim &#8203;probability.</p>
<p data-text-align="center"><lrn-math mathtext="p_{resim} = \frac{0.011 - 0.042}{(0.042)^{2} -0.042} = \frac{-0.031}{-0.040236 } = 0.77045431951"><span>p_{resim} = \frac{0.011 - 0.042}{(0.042)^{2} -0.042} = \frac{-0.031}{-0.040236 } = 0.77045431951</span></lrn-math>
</p>
<p>So &#8203;in &#8203;this &#8203;case, &#8203;we &#8203;will &#8203;re-simulate 77% of&#160;&#8203;ties when the &#8203;initial &#8203;simulation &#8203;results &#8203;in &#8203;a &#8203;tie.&#160; &#8203;By the &#8203;above &#8203;calculation, &#8203;we &#8203;know &#8203;that &#8203;in &#8203;doing &#8203;so &#8203;we &#8203;will &#8203;observe &#8203;a tie &#8203;1.1% &#8203;of &#8203;the &#8203;time, &#8203;as &#8203;required.</p>
<p><a href="https://github.com/whatsacomputertho/fbsim-core/pull/17" target="_blank">I ​implemented ​this ​behavior ​in ​this ​pull ​request</a>. &#8203; &#8203;Then &#8203;I ran another &#8203;<code>fbsim ​game ​benchmark</code> &#8203;with &#8203;this &#8203;in &#8203;place, observing &#8203;the &#8203;following &#8203;results.</p>
<code-sample type="javascript" copy-clipboard-button><template preserve-content="preserve-content">Tie probability
Results:
     0                                                                               100
0    0.0033  0.0039  0.0041  0.0033  0.0021  0.0033  0.0023  0.0012  0.0022  0.0010  0.0005
     0.0051  0.0046  0.0041  0.0050  0.0044  0.0039  0.0030  0.0030  0.0024  0.0015  0.0015
     0.0053  0.0050  0.0057  0.0048  0.0057  0.0044  0.0035  0.0034  0.0029  0.0029  0.0014
     0.0040  0.0057  0.0057  0.0055  0.0060  0.0047  0.0039  0.0064  0.0048  0.0051  0.0030
     0.0055  0.0049  0.0057  0.0060  0.0073  0.0087  0.0078  0.0059  0.0077  0.0051  0.0055
     0.0041  0.0049  0.0061  0.0069  0.0073  0.0075  0.0099  0.0083  0.0079  0.0078  0.0072
     0.0040  0.0046  0.0085  0.0071  0.0091  0.0078  0.0097  0.0094  0.0099  0.0088  0.0094
     0.0025  0.0048  0.0081  0.0069  0.0092  0.0095  0.0109  0.0127  0.0114  0.0120  0.0121
     0.0047  0.0036  0.0061  0.0077  0.0084  0.0093  0.0130  0.0133  0.0156  0.0140  0.0148
     0.0025  0.0040  0.0051  0.0067  0.0099  0.0098  0.0129  0.0141  0.0165  0.0167  0.0183
100  0.0021  0.0024  0.0040  0.0050  0.0075  0.0108  0.0124  0.0148  0.0187  0.0218  0.0260</template></code-sample>
<p>Averaging &#8203;over &#8203;the table, &#8203;we now observe <lrn-math mathtext="p_{tie} = ​0.0071"><span>p_{tie} = ​0.0071</span></lrn-math>
<span class="qv3Wpe" id="cwos"> globally, which in my mind is close enough to the observed global tie probability of roughly 0.006.  In any case, it's a huge improvement from the 7x difference we saw previously.</span></p>
<p><span class="qv3Wpe" id="cwos">Another interesting feature of the above table is that it seems the tie probability increases as the two teams skill levels increase.  That is, an evenly matched game between two bad teams is less likely to result in a tie than an evenly matched game between two good teams.</span></p>
<p><span class="qv3Wpe" id="cwos">I'm still not entirely sure why this is, but think it makes enough intuitive sense to accept for now.  I can picture Josh Allen and Patrick Mahomes going back and forth in a shootout resulting in a tie.  I can't quite say the same about Aiden O'Connell and Drew Lock, though.</span></p>
