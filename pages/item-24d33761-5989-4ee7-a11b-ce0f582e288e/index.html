
<p>While &#8203;using the &#8203;FootballSim MVP &#8203;to &#8203;simulate &#8203;our &#8203;mini football &#8203;league, &#8203;we &#8203;found &#8203;that &#8203;the model &#8203;would &#8203;regularly &#8203;spit &#8203;out &#8203;scores &#8203;that &#8203;are &#8203;unlikely in &#8203;a &#8203;real &#8203;football &#8203;game. &#8203; &#8203;For &#8203;example, &#8203;we &#8203;simulated one &#8203;game &#8203;which ended &#8203;with &#8203;a &#8203;25-22 &#8203;final &#8203;score. &#8203; &#8203;This final &#8203;score &#8203;isn't &#8203;technically &#8203;impossible, &#8203;but each component of &#8203;the &#8203;score &#8203;is &#8203;one &#8203;off &#8203;from &#8203;a &#8203;much &#8203;more &#8203;likely score &#8203;of &#8203;24-21.</p>
<p>Speaking in terms of statistics and probability, one &#8203;instance &#8203;of &#8203;an &#8203;unlikely &#8203;final &#8203;score &#8203;is &#8203;not indicative &#8203;of &#8203;a larger-scale &#8203;problem.&#160; &#8203;But &#8203;having &#8203;simulated &#8203;many &#8203;of &#8203;these games which &#8203;resulted &#8203;in &#8203;an unlikely &#8203;final &#8203;score, &#8203;we &#8203;had &#8203;a &#8203;growing intuitive &#8203;sense &#8203;that certain &#8203;scores &#8203;would be &#8203;observed far &#8203;too &#8203;frequently than &#8203;they &#8203;should &#8203;be. &#8203; &#8203;And &#8203;thus, &#8203;we &#8203;wanted to &#8203;investigate the problem &#8203;further.</p>
<h2 data-original-level="H2" id="header-fefb2e9c-b8a4-c98d-4978-72b9b1daf7b5">Score &#8203;Frequency Improvements</h2>
<h3 id="header-3e56cffc-751c-6efc-74ff-d51456e98628">Exploratory &#8203;Data Analysis</h3>
<p>First, we needed &#8203;to &#8203;find the &#8203;overall frequency &#8203;of &#8203;observed scores &#8203;in &#8203;the real &#8203;world &#8203;data. &#8203; &#8203;We ran&#160;some &#8203;basic &#8203;data &#8203;analysis and produced the &#8203;following &#8203;historgram &#8203;depicting <a href="https://github.com/whatsacomputertho/fbdb-boxscore-eda/blob/main/data/preprocessed/frequency.json" target="_blank">the ​frequency ​of ​real football ​scores</a>.</p>
<media-image source="files/score-frequency.png" card citation="Frequency of real football scores" accent-color="grey" size="wide" offset="none"></media-image>
<p>Here &#8203;we &#8203;see that &#8203;the frequency of the &#8203;score &#8203;24 and &#8203;the &#8203;score &#8203;25 differ by &#8203;a &#8203;factor &#8203;of &#8203;10, and &#8203;the &#8203;frequency of &#8203;the &#8203;score &#8203;22 &#8203;and &#8203;the &#8203;score &#8203;21 &#8203;differ &#8203;by &#8203;a &#8203;factor &#8203;of &#8203;4.&#160; &#8203;So &#8203;the intuitive sense of &#8203;the &#8203;score &#8203;25-22 &#8203;being &#8203;much less likely &#8203;than, say 24-21, &#8203;is &#8203;backed up by this data.&#8203;</p>
<p>Now &#8203;what &#8203;sort of &#8203;distribution &#8203;does &#8203;the model &#8203;produce &#8203;today? &#8203; &#8203;To &#8203;answer &#8203;this &#8203;question, <a href="https://github.com/whatsacomputertho/fbsim-cli/blob/daef08825329d28a86b05e9bfad7e74faa42888f/src/main.rs#L70-L246" target="_blank">​I ​developed ​a ​new ​command ​in ​fbsim-cli</a>, <code>fbsim ​game ​benchmark</code>. &#8203; &#8203;This &#8203;command &#8203;runs &#8203;1.2 million &#8203;simulations, &#8203;and then aggregates the results of &#8203;the &#8203;simulations to show us at &#8203;a &#8203;high &#8203;level &#8203;how &#8203;the &#8203;model performs &#8203;in &#8203;terms &#8203;of &#8203;its statistical properties.&#160; &#8203;Over &#8203;time, &#8203;we &#8203;want &#8203;to &#8203;improve &#8203;the &#8203;model's &#8203;statistical accuracy &#8203;when tested using &#8203;this &#8203;benchmark &#8203;test.</p>
<p>I &#8203;then &#8203;<a href="https://github.com/whatsacomputertho/fbdb-boxscore-eda/pull/9" target="_blank">plotted ​the ​data ​from ​the ​benchmark ​test ​against ​fbsim-core ​v1.0.0-alpha.3</a> in &#8203;another histogram &#8203;plot.</p>
<media-image source="files/base_model_score_frequency.png" card citation="The frequency of observed scores in the base FootballSim model" accent-color="grey" size="wide" offset="none"></media-image>
<p>This &#8203;is &#8203;pretty &#8203;much &#8203;a &#8203;perfect &#8203;normal &#8203;curve, with no &#8203;local &#8203;fuzziness.&#160; This means &#8203;a final score &#8203;of &#8203;25 &#8203;is &#8203;achieved with roughly &#8203;the &#8203;same &#8203;frequency as 24 &#8203;despite &#8203;their &#8203;real-world &#8203;10x difference &#8203;in &#8203;frequency.&#160; &#8203;It's &#8203;also centered &#8203;mysteriously &#8203;high when &#8203;compared &#8203;against &#8203;the &#8203;real &#8203;data, which &#8203;we'll investigate &#8203;shortly.</p>
<h3 id="header-9c4a6670-d911-76bb-4ffb-77272d125e75">Score &#8203;Frequency &#8203;Lookup &#8203;Table &#8203;Filtering</h3>
<p>To attempt &#8203;to &#8203;solve &#8203;the &#8203;frequency &#8203;problem, I decided &#8203;to &#8203;take &#8203;the &#8203;following &#8203;approach.&#160; &#8203;I would <a href="https://github.com/whatsacomputertho/fbsim-core/blob/main/src/freq.rs" target="_blank">pre-load a ​lookup ​table with the actual ​observed ​frequencies for ​each ​score</a>. &#8203; &#8203;Then upon &#8203;generating &#8203;a &#8203;score, &#8203;I &#8203;would &#8203;<a href="https://github.com/whatsacomputertho/fbsim-core/blob/3d166fed5bea327f02931a5b504bfb67dfd2220a/src/sim.rs#L146-L171" target="_blank">adjust ​it ​using the ​lookup ​table</a>.</p>
<ul><li role="textbox">First, I ​​lookup the ​generated ​score N, as ​well ​as ​its neighboring ​scores ​N-1 and ​N+1</li><li role="textbox">​Then ​I ​construct ​a ​categorical ​distribution over ​those ​three ​scores where their probability is scaled relative to their observed frequency from the lookup table</li><li role="textbox">Finally, I ​randomly ​draw a ​score ​from the ​distribution to ​get ​the ​adjusted ​score</li></ul>
<p>This &#8203;seemed &#8203;to have &#8203;a &#8203;positive &#8203;effect &#8203;on &#8203;score &#8203;frequency, &#8203;the &#8203;more likely &#8203;final scores &#8203;began &#8203;to &#8203;appear &#8203;more &#8203;often judging &#8203;by &#8203;intuition. &#8203; &#8203;But &#8203;what sort &#8203;of &#8203;effect &#8203;did &#8203;it &#8203;have &#8203;on &#8203;the &#8203;model's &#8203;statistical performance?</p>
<media-image source="files/adj_model_score_frequency.png" card citation="The frequency of observed scores in the adjusted FootballSim model" accent-color="grey" size="wide" offset="none"></media-image>
<p>This &#8203;had a &#8203;surprisingly &#8203;beneficial &#8203;effect &#8203;on &#8203;the &#8203;local &#8203;behavior &#8203;of &#8203;the &#8203;model.&#160; &#8203;Visually, &#8203;this &#8203;looks &#8203;like &#8203;a &#8203;much &#8203;better &#8203;fit &#8203;in &#8203;comparison &#8203;to &#8203;the original &#8203;model.&#160; &#8203;Further comparing the &#8203;mean &#8203;squared &#8203;errors for &#8203;the &#8203;base &#8203;and &#8203;adjusted &#8203;model score frequencies &#8203;against &#8203;the &#8203;real &#8203;data &#8203;supports &#8203;the &#8203;fact &#8203;that &#8203;this is, &#8203;by and &#8203;large, &#8203;an improvement.</p>
<code-sample type="javascript" copy-clipboard-button><template preserve-content="preserve-content">Base model mean squared error: 7.5289
Adj model mean squared error:  4.1097</template></code-sample>
<p>You &#8203;may &#8203;also &#8203;have &#8203;noticed &#8203;that, between &#8203;the &#8203;base &#8203;model &#8203;and &#8203;the &#8203;adjusted &#8203;model, &#8203;not only did &#8203;the &#8203;model's &#8203;local &#8203;behavior &#8203;change, &#8203;but &#8203;so &#8203;did &#8203;its &#8203;global &#8203;behavior - it &#8203;is &#8203;now &#8203;centered &#8203;more &#8203;appropriately.&#160; &#8203;This &#8203;is &#8203;no &#8203;mistake, &#8203;I &#8203;actually found &#8203;a &#8203;major bug &#8203;in &#8203;the process &#8203;of &#8203;validating the &#8203;model &#8203;with <code>​fbsim ​game ​benchmark</code> &#8203;which I &#8203;fixed &#8203;in between &#8203;producing &#8203;those &#8203;two &#8203;histograms.</p>
<h2 data-original-level="H2" id="header-afba05e7-4ac9-764a-e943-fea0cb88a5b7">Benchmark Test &#8203;Findings &#8203;&#38; &#8203;Bug &#8203;Fixes</h2>
<p>Let's &#8203;take &#8203;a &#8203;quick &#8203;detour to &#8203;talk about &#8203;some tangential findings I made during benchmark testing (and their subsequent bug fixes) &#8203;before &#8203;moving onto the tie frequency enhancements I made.</p>
<h3 data-original-level="H3" id="header-0513e28c-1e40-a2f6-b626-380e5659c81b">Why &#8203;was &#8203;the &#8203;score &#8203;frequency &#8203;distribution &#8203;off-center?</h3>
<p>In &#8203;the &#8203;<code>fbsim ​game ​benchmark</code> &#8203;CLI command, &#8203;I &#8203;produce &#8203;a table &#8203;which &#8203;lists the &#8203;skill &#8203;differential alongside &#8203;the &#8203;observed mean &#8203;and &#8203;standard deviation &#8203;score &#8203;for &#8203;both &#8203;the &#8203;home &#8203;and &#8203;away &#8203;teams. &#8203; &#8203;When &#8203;I &#8203;was &#8203;benchmark &#8203;testing &#8203;the &#8203;model, &#8203;I &#8203;noticed &#8203;that &#8203;the observed mean &#8203;score &#8203;was way off &#8203;from &#8203;what &#8203;it &#8203;should &#8203;have &#8203;been.</p>
<p>Here &#8203;is &#8203;the &#8203;output &#8203;from &#8203;the &#8203;benchmark &#8203;test:</p>
<code-sample type="javascript" copy-clipboard-button><template preserve-content="preserve-content">Home score distribution:
Skill Diff  Mean Score  Std Score
-100        23.1506     7.6162
-80         24.2101     8.1887
-60         25.3185     8.6021
-40         26.4397     8.9407
-20         27.5418     9.2587
0           28.6667     9.4145
20          29.7236     9.5225
40          30.8259     9.5603
60          31.8998     9.4884
80          33.0837     9.3034
100         34.1129     9.0627

Away score distribution:
Skill Diff  Mean Score  Std Score
-100        22.1655     6.4798
-80         23.0604     7.2377
-60         23.9255     7.8504
-40         24.8286     8.3757
-20         25.7620     8.7426
0           26.6536     9.0463
20          27.5140     9.2175
40          28.4326     9.3427
60          29.2490     9.2932
80          30.1968     9.1622
100         31.0702     8.9115</template></code-sample>
<p>While the mean score model &#8203;was &#8203;fit &#8203;against &#8203;this &#8203;data for &#8203;home &#8203;teams:</p>
<code-sample type="json" copy-clipboard-button><template preserve-content="preserve-content">"('score', 'mean')": {
        "0.0": 11.5590551181,
        "0.125": 13.8620155039,
        "0.25": 17.0134387352,
        "0.375": 19.1485774499,
        "0.5": 22.3723214286,
        "0.625": 24.8021442495,
        "0.75": 27.5766828591,
        "0.875": 31.6327372765,
        "1.0": 34.9343434343
}</template></code-sample>
<p>and &#8203;similarly &#8203;for &#8203;away &#8203;teams:</p>
<code-sample type="json" copy-clipboard-button><template preserve-content="preserve-content">"('score', 'mean')": {
        "0.0": 9.3671875,
        "0.125": 12.2220421394,
        "0.25": 14.2501797268,
        "0.375": 16.8838776568,
        "0.5": 19.3722963645,
        "0.625": 22.0789733465,
        "0.75": 25.3302358828,
        "0.875": 28.9319444444,
        "1.0": 31.5263157895
}</template></code-sample>
<p>The &#8203;upper &#8203;end &#8203;of &#8203;the &#8203;spectrum for both home and away teams seems &#8203;to &#8203;be &#8203;roughly &#8203;aligned, but &#8203;the &#8203;lower &#8203;end &#8203;of &#8203;the &#8203;spectrum &#8203;seems &#8203;to &#8203;be extremely misaligned.&#160; &#8203;This &#8203;is &#8203;what &#8203;was &#8203;producing &#8203;the misalignment &#8203;in &#8203;the &#8203;centering of the base model &#8203;score &#8203;frequency &#8203;distribution &#8203;that &#8203;we &#8203;saw &#8203;earlier!</p>
<p>Reflecting on &#8203;this, &#8203;my &#8203;brother &#8203;and &#8203;I &#8203;did &#8203;notice in &#8203;our &#8203;mini &#8203;football &#8203;league &#8203;that &#8203;there &#8203;were &#8203;a &#8203;few surprise contenders which &#8203;had &#8203;beaten multiple opponents &#8203;much &#8203;better &#8203;than &#8203;they &#8203;were. &#8203; &#8203;We figured our &#8203;intuition &#8203;around &#8203;skill &#8203;differential and win probability might &#8203;&#8203;just be &#8203;outright &#8203;wrong, but as it turns out we were just being gas-lit by this bug in the model.</p>
<p>So &#8203;what &#8203;was &#8203;causing &#8203;this bug? &#8203; &#8203;As &#8203;it &#8203;turns &#8203;out, &#8203;it &#8203;was &#8203;a &#8203;stupid &#8203;one - &#8203;a &#8203;simple &#8203;typo! &#8203; &#8203;I &#8203;had &#8203;accidentally <a href="https://github.com/whatsacomputertho/fbsim-core/pull/20/files#diff-ea46a6f4f599d033be920bb2c53a6cae98acb3483cafa763e782cab40bfd9cf3L10-R18" target="_blank">misnamed the ​constant names ​for ​the ​regression ​models' ​intercepts ​and coefficients</a>, which &#8203;resulted &#8203;in &#8203;the &#8203;intercept &#8203;being treated &#8203;as the &#8203;coefficient, &#8203;and &#8203;vice &#8203;versa. &#8203; &#8203;<a href="https://github.com/whatsacomputertho/fbsim-core/pull/20" target="_blank">I ​fixed ​that ​issue ​in ​this ​PR</a>, &#8203;and &#8203;subsequently &#8203;saw &#8203;much &#8203;better &#8203;results &#8203;in &#8203;the benchmark &#8203;testing.</p>
<code-sample type="javascript" copy-clipboard-button><template preserve-content="preserve-content">Home score distribution:
Skill Diff  Mean Score  Std Score
-100        11.2780     7.1944
-80         13.4964     7.8423
-60         15.7159     8.3578
-40         18.0300     8.8404
-20         20.3076     9.1898
0           22.5839     9.4275
20          24.9194     9.5291
40          27.2036     9.5548
60          29.5982     9.4513
80          31.8540     9.2936
100         34.2193     9.0829

Away score distribution:
Skill Diff  Mean Score  Std Score
-100        9.1762      6.0629
-80         11.3444     6.8845
-60         13.4862     7.5883
-40         15.6616     8.1947
-20         17.7987     8.6510
0           20.0065     9.0046
20          22.2411     9.2066
40          24.4323     9.3496
60          26.7023     9.3638
80          28.9100     9.1980
100         31.1470     8.9210</template></code-sample>
<h3 data-original-level="H3" id="header-0b3a7445-4360-355e-a9c8-4472991ce4fa">Simulation &#8203;speed &#8203;regression</h3>
<p>While comparing the output of &#8203;fbsim-core &#8203;v1.0.0-alpha.3 (pre-score frequency enhancement) &#8203;and &#8203;v1.0.0-alpha.13 in &#8203;terms &#8203;of &#8203;their &#8203;statistical &#8203;performance, I &#8203;noticed that there &#8203;was &#8203;a &#8203;huge &#8203;difference &#8203;in &#8203;how &#8203;long &#8203;it &#8203;took &#8203;to &#8203;simulate &#8203;1.2 million &#8203;games &#8203;across &#8203;the &#8203;versions.</p>
<ul><li role="textbox">In ​v1.0.0-alpha.3, it ​took ​<b>5.63 ​seconds</b> ​to ​simulate 1.2 ​million ​games</li><li role="textbox">In ​v1.0.0-alpha.13, it ​took ​<b>90.29 ​seconds</b> ​to ​simulate ​1.2 ​million ​games</li></ul>
<p>So &#8203;in &#8203;the &#8203;process &#8203;of &#8203;fixing &#8203;the &#8203;statistical &#8203;performance &#8203;issue, &#8203;I &#8203;made a &#8203;major &#8203;tradeoff &#8203;in &#8203;terms &#8203;of &#8203;speed. &#8203; &#8203;What &#8203;happened?&#160; Well, &#8203;looking back &#8203;at &#8203;the &#8203;source &#8203;code, &#8203;I &#8203;found &#8203;that &#8203;I'm &#8203;doing &#8203;some &#8203;pretty &#8203;stupid &#8203;things &#8203;that are &#8203;likely &#8203;causing &#8203;this speed &#8203;regression.</p>
<code-sample type="javascript" copy-clipboard-button><template preserve-content="preserve-content">/// Filters the box score by score frequency.  The score's nearest
    /// neighbors and their frequency are retrieved to construct a probability
    /// mass function for a categorical distribution.  That distribution is
    /// then sampled for the real score.
    fn filter_score(&amp;self, score: i32, rng: &amp;mut impl Rng) -&gt; i32 {
        // If the score is 0, just return 0 as 1 is impossible
        if score == 0 {
            return 0
        }

        // Create a score frequency lookup table
        let mut freq_lut = ScoreFrequencyLookup::new();
        freq_lut.create();

        // Get the nearest neighbors of the score
        let low = freq_lut.frequency(score - 1).unwrap();
        let mid = freq_lut.frequency(score).unwrap();
        let high = freq_lut.frequency(score + 1).unwrap();
        
        // Construct a categorical distribution
        let dist = Categorical::new(&amp;[low as f64, mid as f64, high as f64]).unwrap();
        let score_adjustment_r: f64 = dist.sample(rng);
        let score_adjustment = (score_adjustment_r as i32) - 1_i32;
        let adj_score = score + score_adjustment;
        adj_score
    }</template></code-sample>
<p>First, I &#8203;am &#8203;allocating &#8203;and &#8203;de-allocating &#8203;the &#8203;score &#8203;frequency &#8203;distribution &#8203;every &#8203;time &#8203;I run &#8203;a &#8203;simulation. &#8203; &#8203;Alternatively, I &#8203;could &#8203;simply store &#8203;a &#8203;static &#8203;reference &#8203;to &#8203;an immutable lookup table &#8203;that &#8203;I only instantiate &#8203;once.</p>
<p>&#8203;Second, &#8203;I &#8203;am &#8203;using a &#8203;<code>BTreeMap</code> to store the lookup table, which has O(log N) lookup performance, &#8203;and &#8203;not &#8203;a &#8203;<code>HashMap</code> which has O(1) lookup performance.&#160; &#8203;Granted, &#8203;my &#8203;lookup &#8203;table is &#8203;only &#8203;size-80 &#8203;so &#8203;this &#8203;may &#8203;not &#8203;be &#8203;all &#8203;that &#8203;much &#8203;of a &#8203;contributor, but &#8203;it's &#8203;a &#8203;simple &#8203;change &#8203;to &#8203;switch &#8203;between &#8203;collections &#8203;under &#8203;the &#8203;hood, &#8203;so &#8203;may &#8203;as &#8203;well &#8203;do so while &#8203;I'm &#8203;looking &#8203;at &#8203;performance.</p>
<p>I &#8203;released fbsim-core &#8203;v1.0.0-alpha.14 &#8203;<a href="https://github.com/whatsacomputertho/fbsim-core/pull/24" target="_blank">which includes these ​changes</a> &#8203;and &#8203;then &#8203;re-ran &#8203;the &#8203;benchmark &#8203;testing.&#160; &#8203;This time, &#8203;I &#8203;was able &#8203;to &#8203;run &#8203;1.2 &#8203;million &#8203;simulations in &#8203;just &#8203;<b>8.18 ​seconds</b>, &#8203;bringing &#8203;us &#8203;back &#8203;down &#8203;into &#8203;a &#8203;reasonable &#8203;range.</p>
<h2 id="header-4018027a-7794-69f4-d6b9-fdbb6f1f02bb">Tie &#8203;Frequency &#8203;Improvements</h2>
<p>The &#8203;natural &#8203;question &#8203;we &#8203;asked &#8203;upon &#8203;making &#8203;the aforementioned improvement &#8203;to &#8203;&#8203;score &#8203;frequency was, &#8203;how &#8203;does &#8203;this &#8203;impact the &#8203;frequency &#8203;of &#8203;ties? &#8203; &#8203;If &#8203;some scores are more likely than others, &#8203;does &#8203;that now&#160;&#8203;mean &#8203;that &#8203;we will observe more &#8203;ties &#8203;which &#8203;would &#8203;have &#8203;otherwise been &#8203;one-point &#8203;victories?</p>
<p>To &#8203;answer &#8203;these &#8203;questions, &#8203;we &#8203;again &#8203;compared the <code>​fbsim ​game ​benchmark</code> &#8203;testing against &#8203;real-world &#8203;data.</p>
<h3 id="header-4ef0fba9-80c9-fa79-7060-c2a79320f924">Exploratory &#8203;Data &#8203;Analysis</h3>
<p>asdf</p>
<h3 id="header-6febb2b5-2dff-23d9-81df-649c48511f36">Tie-Resimulation</h3>
<p>asdf</p>
